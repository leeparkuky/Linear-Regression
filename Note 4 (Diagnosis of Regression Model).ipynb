{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(latex2exp)\n",
    "df<- read_table2(\"C:/Users/Lee Sak Park/Desktop/Spring 2020/Linear Model/Notes/data_set.txt\", \n",
    "                 col_names = FALSE)\n",
    "colnames(df) = c(\"Y\",'X1','X2','X3')\n",
    "y = df$Y %>% as.matrix\n",
    "J = rep(1, length(y))\n",
    "X = cbind(J, df[c('X1','X2','X3')]) %>% as.matrix\n",
    "colnames(y) = NULL\n",
    "colnames(X) = NULL\n",
    "H = X %*% solve(t(X) %*% X) %*% t(X)\n",
    "h = diag(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> <b> $\\S$ 10.3 Identifying Outlying X Observations - Hat Matrix Leverage Values </b> </font>\n",
    "\n",
    "<font size = 3> <b>Studentized Residuals and Deleted Residuals - To find outliers </b> </font>\n",
    "\n",
    "1. Studentized Residuals\n",
    "\n",
    "<center> $r_i = \\frac{e_i}{s \\{ e_i \\}}$, where $ s \\{ e_i \\} = \\sqrt{MSE \\cdot (1 - h_{ii})}  $ </center> \n",
    "\n",
    "and <b> $r_i \\sim t(n-p)$ </b>\n",
    "\n",
    "\n",
    "\n",
    "2. Deleted Residuals\n",
    "\n",
    "<b> <u> Definition </u> </b> $d_i$:\n",
    "\n",
    "<center> $d_i = Y_i - \\hat{Y}_{i(i)}$ </center>\n",
    "\n",
    "\n",
    "<center> $d_i = \\frac{e_i}{1-h_{ii}}$ </center>\n",
    "\n",
    "\n",
    "<b> <u> Definition </u> </b> $s^2 \\{ d_i \\}$:\n",
    "\n",
    "<center> $s^2 \\{ d_i \\} = MSE_{(i)}\\cdot (1+ X^t_{i} ( X^t_{(i)} X_{(i)} )^{-1} X_{i}) = \\frac{MSE_{(i)}}{1-h_{ii}} $ </center>\n",
    "\n",
    "\n",
    "$\\Rightarrow \\frac{d_i}{s \\{ d_i \\}} \\sim t(n-p-1) $\n",
    "\n",
    "\n",
    "<b> <u> Test for outlier </u> </b>\n",
    "\n",
    "Let $t_i = \\frac{d_i}{s \\{ d_i \\}} = \\frac{e_i}{\\sqrt{MSE_{(i)} \\cdot (1-h_{ii})}} \\sim t(n-p-1)$\n",
    "\n",
    "\n",
    "Since $(n-p) \\cdot MSE = SSE = SSE_{(i)} + d_i = (n-p-1) \\cdot MSE_{(i)} + \\frac{e^2_i}{(1-h_{ii})} $, it follows that\n",
    "\n",
    "\n",
    "<center>$t_i = \\frac{d_i}{s \\{ d_i \\}}  = e_i \\big[ \\frac{n-p-1}{SSE \\cdot (1-h_{ii}) - e_i^2} \\big]^{1/2} $</center>\n",
    "\n",
    "\n",
    "\n",
    "<font size = 2.2> <b>  Note: for the test, use either Bonferroni critical value or Tucky's  </b> </font>\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "<font size = 3> <b>Property of the hat matrix </b> </font>\n",
    "\n",
    "\n",
    "1. <center> $ 0 \\leq h_{ii} \\leq 1$ and $\\Sigma_{i=1}^{n} h_{ii} = p$ </center>\n",
    "\n",
    "\n",
    "2. $\\bar{Y}_i$ is a linear combination of the observed $Y$ values, because <center> $\\hat{Y} = H Y  \\Rightarrow \\bar{Y}_i = h_{i1} Y_1 + h_{i2} Y_2 + \\dots + h_{in} Y_n $</center>\n",
    "\n",
    "<font size = 1.9> <b> Implication </b> : the larger $h_{ii}$, the more important is $Y_i$ in determining $\\hat{Y}_i$ </font>\n",
    "\n",
    "3. The larger $h_{ii}$, the smaller $\\sigma^2 \\{ e_i \\} = \\sigma^2 (1-h_{ii})$\n",
    "\n",
    "\n",
    "4. $\\bar{h} = \\frac{p}{n}$\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "<font size = 3> <b> Detecting Outlying Cases </b> </font>\n",
    "\n",
    "Leverage values, $h_{ii}$'s, <b> greater </b> than $\\frac{2p}{n} = 2 \\bar{h}$ are considered to indicate outlying cases with regard to their X values\n",
    "\n",
    "<hr>\n",
    "\n",
    "<font size = 3> <b> Use of Hat Matrix to Identify Hidden Extrapolation </b> </font>\n",
    "\n",
    "a leverage of the new set of X values = <center> $h_{new, new} = X^t_{new} (X^t X )^{-1} X_{new}$ </center>\n",
    "\n",
    "If $h_{new, new}$ is well within the range of leverage values $h_{i,i}$, no extrapolation is involved.\n",
    "\n",
    "However, if $h_{new, new}$ is much larger than the leverage values, an extrapolation is indicated\n",
    "\n",
    "<hr> \n",
    "\n",
    "\n",
    "\n",
    "<font size = 3> <b> Influence on Single Fitted Value - DFFITS </b> </font>\n",
    "\n",
    "The <b> DFFITS </b> measure considers the influence of the i$^{th}$ case on the fitted value $\\hat{Y}_i$.\n",
    "\n",
    "<center> $(DFFITS)_i = \\frac{\\hat{Y}_i -\\hat{Y}_{i(i)}}{\\sqrt{MSE_{(i)} h_{ii}}} = t_i \\big( \\frac{h_{ii}}{1-h_{ii}}  \\big)^{1/2}$  </center>\n",
    "\n",
    "<font size = 1.9> Note: $\\sigma^2 \\{ \\hat{Y}_i \\} = \\sigma^2 h_{ii} \\Rightarrow \\hat{\\sigma^2 \\{ \\hat{Y}_i \\}} = MSE \\cdot h_{ii}$ </font>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<font size = 3> <b> Influence on All Fitted Value - Cook's Distance ($D_i$) </b> </font>\n",
    "\n",
    "<center> $D_i = \\frac{\\Sigma_{j=1}^n (\\hat{Y}_j - \\hat{Y}_{j(i)})^2}{p\\cdot MSE} = \\frac{(\\hat{Y} - \\hat{Y}_{(i)})^t (\\hat{Y} - \\hat{Y}_{(i)})}{p \\cdot MSE} = \\frac{e^2_i}{p \\cdot MSE} \\big[ \\frac{h_{ii}}{(1-h_{ii})^2} \\big] \\sim F_{(p,n-p)}$   </center>\n",
    "\n",
    "\n",
    "<u> Another equation </u>\n",
    "\n",
    "<center> $D_i = \\frac{ (b - b_{(i)})^t X^t X (b- b_{(i)})  }{ p \\cdot MSE  }      $   </center>\n",
    "\n",
    "and  $\\frac{ (b - B)^t X^t X (b- B)  }{ p \\cdot MSE  }  \\sim F_{(1- \\alpha; p, n-p)}    $  \n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "<font size = 3> <b> Influence on the Regression Coefficients - DFBETAS </b> </font>\n",
    "\n",
    "<center> $(DFBETAS)_{k(i)} = \\frac{b_k - b_{k(i)}}{\\sqrt{MSE_(i) c_{kk}}}$ </center>\n",
    "\n",
    "where $b_{k(i)}$ = the regression coefficient obtained when the i$^{th}$ case is omitted\n",
    "\n",
    "$c_{kk}$ = the $k^{th}$ diagonal element of $(X^t X)^{-1}$\n",
    "\n",
    "<font size = 1.9> <u> Note: $\\sigma^2 \\{ b_k \\} = \\sigma^2 c_{kk}$  </u>  </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Example 1. Detecting the outlying cases </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3</li>\n",
       "\t<li>5</li>\n",
       "\t<li>16</li>\n",
       "\t<li>21</li>\n",
       "\t<li>22</li>\n",
       "\t<li>43</li>\n",
       "\t<li>44</li>\n",
       "\t<li>48</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3\n",
       "\\item 5\n",
       "\\item 16\n",
       "\\item 21\n",
       "\\item 22\n",
       "\\item 43\n",
       "\\item 44\n",
       "\\item 48\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3\n",
       "2. 5\n",
       "3. 16\n",
       "4. 21\n",
       "5. 22\n",
       "6. 43\n",
       "7. 44\n",
       "8. 48\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  3  5 16 21 22 43 44 48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = c()\n",
    "for (r in 1:dim(H)[1]){\n",
    "    if(diag(H)[r] > 8/dim(H)[1]){\n",
    "    result = c(result, r)    \n",
    "    }}\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Example 2. Testing DFFITS </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'X' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'X' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "dffits = rep(NA, dim(X)[1])\n",
    "model = lm(Y~., data = df)\n",
    "for(r in 1:dim(H)[1]){\n",
    "    e = model$residuals[[r]]\n",
    "    n = dim(X)[1]\n",
    "    p = dim(X)[2]\n",
    "    SSE = model$residuals^2 %>% sum()\n",
    "    dffits[r] = e*( (n-p-1 ) / ( SSE * (1-h[r] ) - e^2) )^(1/2) * ( ( h[r] ) / ( 1 - h[r] ) )^(1/2)   \n",
    "}\n",
    "\n",
    "threshold = sqrt(dim(X)[2]/dim(X)[1]) *2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "2"
      ],
      "text/latex": [
       "2"
      ],
      "text/markdown": [
       "2"
      ],
      "text/plain": [
       "[1] 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if it is considered as a midium size data-set\n",
    "sum(abs(dffits) > threshold)\n",
    "# if it is considered as a small size data-set\n",
    "sum(abs(dffits) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Example 3: Cook's distance </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooks = rep(NA, dim(X)[1])\n",
    "model = lm(Y~., data = df)\n",
    "for(r in 1:dim(H)[1]){\n",
    "    e = model$residuals[[r]]\n",
    "    n = dim(X)[1]\n",
    "    p = dim(X)[2]\n",
    "    MSE = (summary(model)[[6]])^2\n",
    "    cooks[r] = e^2/(p*MSE)  *  (h[r]/(1-h[r])^2)   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANIAAACvCAMAAAC/+3BvAAAABlBMVEUAAAD///+l2Z/dAAAA\nCXBIWXMAAArDAAAKwwE0KSSrAAADq0lEQVR4nO2a25asIAxE8f9/+qzTigIGSLhOuar6oWfk\nlo1JQFp3fE5utwHjRSQEEQlBREIQkRBEJAQRCUFEQhCREEQkBBEJQURCEJEQRCQEEQlBREIQ\nkRBEJAQRCUFEQhCREEQkBBEJQURCEJEQRCQEEQlBjUhutyYgtTXL9GTvjUhxuXyfgZFc8n0o\nfNmops5GIumaTRcqUuH+bYulPgctRdmujNcW+armRIrLT99piqVOpEmx9LPKtaaHoclePb4q\n47kPJvHXbAMj3Uz3/8N3D03609tW47jOh0KhTmPXlSEn6c6hA5CUsdSbtjVmjEJSNiNSw7gD\nYsm4bV2VC7c8XMyF24HU6oK/mahPx44HdTPS2affU2rtspZdIzU9AlqRrvorkJqbGWNpEpLB\nhrGh70Kvmx1L5WaDstqFYvXTlrJas2hmO6SNu2CcyUjdZEqksNoapI7NUG0yglALxy/Z1mDE\ne6iu/V0RShhgJJK01L4n0apyW8GzF61L4kzrAiyHlJ2sLUvtU88Y+fe1ZLFSj78IyZ9w5u6Z\nbHR+QlYgZVb9J7L/l0kelIU8NiNl92bee36fd4XkSjAx5S3FWiTJjAcpTZZRX9HEVPN6S5mh\n2WOM7Czn9PuvpJ3Qi9yBzuwakvZ56XYZYz6O+s4jpRc7kHKrdX1dfC6EU1JM6ldN2XPnIdUf\n1F8ucn7S0nzaljpceJfq5xAJUmCmtCMoR+F7/JLN2fJiLMn2JjWTKuekO9lMYSCh+cyMl0MK\njU2m5EoBQvYrpf+4+XokyauOcH7jBVXs/w45KSnOcjyfnV5JquxX59cV8rlADGjzvTQi5dOD\nS0pdVCbsfp5b5OcoczdfHcZFvbHUhpTNuy7+K2ucVPDyv5rNlWILUnWjUEeqrlojY+lZapOr\nGrNe1hkOlcYhjW3mWzccj81H2q1+JGkNNPVnq27svKVW/6hEsnVuq5V1XVik3LpEJCJtiqW/\nKyhjdSISgoiEICIhqP15KdeXdhVzlR8GX7WdsnYbknho4CrnCWIXlurK2uOQXO2IROxGWT09\niFHUNUrueiaS079bsRHJ8gKIxU1B7pKlNpGCVp1Itow33/G2rEva2tw9IIhICCISgoiEICIh\niEgIIhKCiIQgIo0aaOawROoayPkz5uvVN/+G4WAbliI5f8wTwFReYG4baY1CiPjrQ0jBOffo\nkdZIvEvHx+7S8R3Hi37RQ85460QkBBEJQURCEJEQRCQEEQlBREIQkRD0DxNMijsPAiv3AAAA\nAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width = 3, repr.plot.height = 2.5, repr.plot.res = 70)\n",
    "qf(cooks, dim(X)[2],dim(X)[1]) %>% plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Example 4: DFBETAS </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbetas = matrix(rep(NA, length(X)), nrow = dim(X)[1])\n",
    "b = (model$coefficients %>% as.vector)\n",
    "xx = (X %>% t()) %*% X %>% solve() %>% diag()\n",
    "for(i in 1:dim(X)[1]){\n",
    "    new_df = df[c(-i),]\n",
    "    new_model = lm(Y~., data = new_df)\n",
    "    new_b = new_model$coefficients %>% as.vector\n",
    "    for (k in 1:dim(X)[2]){\n",
    "        c = xx[k]\n",
    "        MSE = (summary(new_model)[[6]])^2\n",
    "        num = b[k] - new_b[k]\n",
    "        den = (  MSE * c   )^.5\n",
    "        dfbetas[i,k] = (num/den)        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = c()\n",
    "\n",
    "for(n in 1:dim(dfbetas)[1]){\n",
    "    count = 0\n",
    "    for(m in 1:dim(dfbetas)[2]){\n",
    "        if(dfbetas[n,m]>1){\n",
    "            count = count+1\n",
    "        }\n",
    "    }\n",
    "    if(count > 0){\n",
    "        result = c(result, n)\n",
    "    }\n",
    "}\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(dfbetas>1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> <b> $\\S$ 10.5 Multicollinearity Diagnostics - Variance Inflation Factor </b> </font>\n",
    "\n",
    "<b> Derivation </b>\n",
    "\n",
    "<center> $ \\sigma^2 \\{  b \\} = \\sigma^2 (X^t X)^{-1} $ </center>\n",
    "\n",
    "\n",
    "With the standardized regression coefficients, \n",
    "<center>$ \\sigma^2 \\{  b^* \\} = (\\sigma^*)^2 ({X^{*}}^t X^*)^{-1} =  (\\sigma^*)^2 r_{XX}^{-1} $</center> \n",
    "\n",
    "\n",
    "Let $(VIF)_k$ be the k$^{th}$ diagonal element of the matrix $r_{XX}^{-1}$. Then,\n",
    "\n",
    "\n",
    "<center> $ \\sigma^2 \\{  b^*_k \\} =  (\\sigma^*)^2 (VIF)_k $ </center>\n",
    "\n",
    "\n",
    "<b> <u>Note</u></b> that $(VIF)_k = (1- R-K^2)^{-1}$, k = 1,2, $\\dots$, p-1\n",
    "\n",
    "where $R_k^2$ is the coefficient of multiple determination when $X_k$ is regressed on the p-2 other $X$ variables in the model.\n",
    "\n",
    "\n",
    "\n",
    "Therefore, $ \\sigma^2 \\{  b^*_k \\} $ becomes, \n",
    "\n",
    "\n",
    "<center> $ \\sigma^2 \\{  b^*_k \\}  = \\frac{(\\sigma^*)^2}{1-R_k^2}$ </center> \n",
    "\n",
    "\n",
    "\n",
    "<b> <u>Rule of Thumb</u> </b>\n",
    "\n",
    "The largest VIF value among all X variables is often used as an indicator of the severity of multicollinearity.\n",
    "\n",
    "A maximum VIF value in excess of 10 is frequently taken as an indication that mulitcollinearity may be unduly influencing the least square estimates\n",
    "\n",
    "\n",
    "\n",
    "<b> <u>Definition</u> </b>($\\overline{VIF}$) \\< the mean of the VIF \\>\n",
    "    \n",
    "$\\overline{VIF} = \\frac{\\Sigma_{k=1}^{p-1} VIF_k}{p-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>X1</dt>\n",
       "\t\t<dd>1.00859588041048</dd>\n",
       "\t<dt>X2</dt>\n",
       "\t\t<dd>1.01959822603054</dd>\n",
       "\t<dt>X3</dt>\n",
       "\t\t<dd>1.01436408017335</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[X1] 1.00859588041048\n",
       "\\item[X2] 1.01959822603054\n",
       "\\item[X3] 1.01436408017335\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "X1\n",
       ":   1.00859588041048X2\n",
       ":   1.01959822603054X3\n",
       ":   1.01436408017335\n",
       "\n"
      ],
      "text/plain": [
       "      X1       X2       X3 \n",
       "1.008596 1.019598 1.014364 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VIF(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
